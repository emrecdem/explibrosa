{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of librosa library for speech processing\n",
    "\n",
    "\n",
    "### Installation\n",
    "Librosa installation instructions can be found here: https://librosa.github.io/librosa/install.html\n",
    "\n",
    "### Data format\n",
    "In the example below we will work with .wav format data. Data in our project was provided in .aiff format, I converted them with ffmpeg using the following command line instruction:\n",
    "\n",
    "`ffmpeg -i filename.mp3 newfilename.wav`\n",
    "\n",
    "The first half of this notebook derived from https://www.kaggle.com/jerrypeng/dsp-tutorial-3-demos-for-speech-processing\n",
    "\n",
    "Assumption is that you work in Python 3 environment\n",
    "If you want to be able to play the audio sounds within Jupyter then open your notebook with: jupyter notebook --NotebookApp.iopub_data_rate_limit=10000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the following Python libraries\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "Audio-files are assumed to be stored in wav format in a 'data' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get wavfilename of the first file in the data folder\n",
    "audioFilePath = os.listdir(\"data\")\n",
    "wavfilename = 'data/' + audioFilePath[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the wav file with librosa\n",
    "wave, fs = librosa.load(wavfilename, sr=None)\n",
    "print('sample frequency = ' + str(fs/1000) + ' kHertz')\n",
    "recordingDurationMinutes = (wave.size / fs) / 60\n",
    "print('duration of recording = ' + str(round(recordingDurationMinutes,1)) + ' minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select subset\n",
    "Select middle 2 minutes of the recording for demo purposes. In a real application we will have to implement this as a moving window through the recording to handle memory constrains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "midpoint = round(wave.size / 2)\n",
    "wave = wave[(midpoint-(round(fs * 60 * 0.1))+1):(midpoint+(round(fs * 60 * 0.1)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.waveplot(wave, sr=fs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Play the sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(wave,rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STFT = librosa.stft(wave, n_fft=2048) # Short-time Fourier transform (STFT)\n",
    "mag, phase = librosa.magphase(STFT) #Separate a complex-valued spectrogram into its magnitude and phase components\n",
    "dBspectrogram = librosa.amplitude_to_db(mag, ref=np.max) # Convert an amplitude spectrogram to dB-scaled spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "librosa.display.specshow(dBspectrogram, x_axis='time',sr=fs)\n",
    "plt.title('log Power spectrogram')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate some features per frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame_len = int(20 * fs /1000) # 20ms\n",
    "frame_shift = int(10 * fs /1000) # 10ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate RMS energy for each frame\n",
    "rmse = librosa.feature.rmse(wave, frame_length=frame_len, hop_length=frame_shift)\n",
    "rmse = rmse[0]\n",
    "rmse = librosa.util.normalize(rmse, axis=0) # normalize first axis to -1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate zero-crossing rate\n",
    "zrc = librosa.feature.zero_crossing_rate(wave, frame_length=frame_len, hop_length=frame_shift, threshold=0)\n",
    "zrc = zrc[0]\n",
    "zrc = librosa.util.normalize(zrc, axis=0) # normalize first axis to -1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 seconds => 1200 frames of 10ms\n",
    "len(rmse.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function needed for pitch detection\n",
    "def extract_max(pitches, shape):\n",
    "    new_pitches = []\n",
    "    for i in range(0, shape[1]):\n",
    "        new_pitches.append(np.max(pitches[:,i]))\n",
    "    return new_pitches\n",
    "\n",
    "def smooth(x,window_len=11,window='hanning'):\n",
    "        if window_len<3:\n",
    "                return x\n",
    "        if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "                raise(ValueError, \"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n",
    "        s=np.r_[2*x[0]-x[window_len-1::-1],x,2*x[-1]-x[-1:-window_len:-1]]\n",
    "        if window == 'flat': #moving average\n",
    "                w=np.ones(window_len,'d')\n",
    "        else:\n",
    "                w=eval('np.'+window+'(window_len)')\n",
    "        y=np.convolve(w/w.sum(),s,mode='same')\n",
    "        return y[window_len:-window_len+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Slice a time series into overlapping\n",
    "frames = librosa.util.frame(wave, frame_length=frame_len, hop_length=frame_shift)\n",
    "# Pitch tracking on thresholded parabolically-interpolated STFT:\n",
    "pitches, magnitudes = librosa.core.piptrack(wave, sr=fs, hop_length=frame_shift, threshold=0.75)\n",
    "\n",
    "pitch_track = extract_max(pitches, pitches.shape)\n",
    "pitch_smoothtrack = smooth(pitch_track, window_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RMSE and ZCR\n",
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(rmse.T)\n",
    "plt.title('RMS Energy')\n",
    "plt.xticks([])\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(pitch_smoothtrack)\n",
    "plt.title('Pitch (Hertz)')\n",
    "plt.xticks([])\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(zrc.T)\n",
    "plt.title('zero-corssing rate')\n",
    "plt.xticks([])\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "t = np.linspace(0, len(wave)/fs, len(wave))\n",
    "plt.plot(t, wave)\n",
    "plt.title('Waveform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set threshold of speech and silence\n",
    "plt.figure(figsize=(5, 5))\n",
    "n, bins, patches = plt.hist(rmse.T, 20, facecolor='g', alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame_idxs = np.where( (rmse > 0.1) | (zrc > 0.4) )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get start-points and end-points of speech\n",
    "def getboundaries(frame_idxs):\n",
    "    start_idxs = [frame_idxs[0]]\n",
    "    end_idxs = []\n",
    "\n",
    "    shapeofidxs = np.shape(frame_idxs)\n",
    "    for i in range(shapeofidxs[0]-1):\n",
    "        if (frame_idxs[i + 1] - frame_idxs[i]) != 1:\n",
    "            end_idxs.append(frame_idxs[i])\n",
    "            start_idxs.append(frame_idxs[i+1])\n",
    "\n",
    "    end_idxs.append(frame_idxs[-1])\n",
    "    # del the last boundaries if it is both start point and end point.\n",
    "    if end_idxs[-1] == start_idxs[-1]:\n",
    "        end_idxs.pop()\n",
    "        start_idxs.pop()\n",
    "    assert len(start_idxs) == len(end_idxs), 'Error! Num of start_idxs doesnt match Num of end_idxs.'\n",
    "    start_idxs = np.array(start_idxs)\n",
    "    end_idxs = np.array(end_idxs)\n",
    "    start_t = start_idxs * frame_shift / fs\n",
    "    end_t = end_idxs * frame_shift / fs\n",
    "    return start_t, end_t\n",
    "\n",
    "start_t, end_t = getboundaries(frame_idxs)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "t = np.linspace(0, len(wave)/fs, len(wave))\n",
    "plt.plot(t, wave)\n",
    "plt.title('Waveform with start (red) and end (green) times of speech')\n",
    "plt.ylim(-0.1,0.1)\n",
    "for s, e in zip(start_t, end_t):\n",
    "    plt.axvline(x=s, color='red') # red vertical line\n",
    "    plt.axvline(x=e, color='green') # green vertical line\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chromagram (more suitable for for a music interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hopLength = 100\n",
    "chroma = librosa.feature.chroma_stft(y=wave, sr=fs, n_fft=2048, hop_length=hopLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(chroma, y_axis='chroma', x_axis='time', sr = fs,hop_length= hopLength)\n",
    "plt.colorbar()\n",
    "plt.title('Chromagram')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Mel Frequency Cepstral Coefficients (MFCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mfccs = librosa.feature.mfcc(y=wave, sr=fs, n_mfcc = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "librosa.display.specshow(mfccs, x_axis='time',sr=fs)\n",
    "plt.colorbar()\n",
    "plt.title('MFCC 13')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Calculate MFCC again, but now stepwise to better understand the underlying process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Small time windows from a speech signal are processed with a Short Time Fourier Transform (STFT) resulting in a Frequency spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STFT = librosa.stft(wave, n_fft=2048)\n",
    "mag, phase = librosa.magphase(STFT)\n",
    "plt.figure(figsize=(14,4))\n",
    "librosa.display.specshow(librosa.amplitude_to_db(mag, ref=np.max), x_axis='time',sr=fs)\n",
    "plt.title('Power spectrogram')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.\tThe Frequency spectrum is then processed with a mel scale filter resulting in a mel frequency spectrum. A mel scale filter constitutes of multiple bandpass filters, and the power of each filter band is computed. The spacing between the filters is non-linear to mimic the human auditory system (mel scale), here the number, the shape, and the center frequency of the band-pass filters can be varied. There is debate in the literature on what combination is best, suggesting that overlapping rectangular shaped filters are best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = np.abs(STFT)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out two different n_mels setting (the number of bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S128 = librosa.feature.melspectrogram(S=D,n_mels=128)\n",
    "S13 = librosa.feature.melspectrogram(S=D,n_mels=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualise this to see what the data at this stage looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(2, 1, 1)\n",
    "librosa.display.specshow(S128, y_axis='mel', x_axis='time',sr=fs)\n",
    "plt.title('Mel spectrogram, N mels = 128')\n",
    "plt.tight_layout()\n",
    "plt.subplot(2, 1, 2)\n",
    "librosa.display.specshow(S13, y_axis='mel', x_axis='time',sr = fs)\n",
    "plt.title('Mel spectrogram, N mels = 13')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. The mel frequency spectrum is then processed by taking the log to mimic the human perception of loudness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S128db = librosa.power_to_db(S128)\n",
    "S13db = librosa.power_to_db(S13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "librosa.display.specshow(S128db, y_axis='mel', x_axis='time',sr=fs)\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel spectrogram, N mels = 128')\n",
    "plt.tight_layout()\n",
    "plt.subplot(2, 1, 2)\n",
    "librosa.display.specshow(S13db, y_axis='mel', x_axis='time',sr = fs)\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel spectrogram, N mels = 13')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Next a Discrete Cosine Transform is taken which results in cepstral coefficients. This aims to eliminate the speaker dependent characteristics. The cepstrum can be interpreted as a spectrum of a spectrum. Explaination for DCT instead of FFT:  Instead of the Fourier Transform the discrete cosine transform can be used because the absolute value of the spectrum, respectively the periodic continuation of the signal, is real and symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mfccs128 = librosa.feature.mfcc(S=S128db,sr=fs, n_mfcc = 128)\n",
    "mfccs13 = librosa.feature.mfcc(S=S13db,sr=fs, n_mfcc = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "librosa.display.specshow(mfccs128, y_axis='mel', x_axis='time',sr=fs)\n",
    "plt.colorbar()\n",
    "plt.title('MFCC 128')\n",
    "plt.tight_layout()\n",
    "plt.subplot(2, 1, 2)\n",
    "librosa.display.specshow(mfccs13, y_axis='mel', x_axis='time',sr=fs)\n",
    "plt.colorbar()\n",
    "plt.title('MFCC 13')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
